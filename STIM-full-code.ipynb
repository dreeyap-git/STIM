{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a9a40-36ea-4947-ab14-8756839dbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORT-TERM INVENTORY MODEL (STIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "977e88ae-9e2c-4b23-bead-636c81e3d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CSV files...\n",
      "Preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# PRE-PROCESSING CODE\n",
    "# ---------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Fetching CSV files...')\n",
    "\n",
    "# Define folder path and read all CSVs inside\n",
    "folder = r'C:\\Users\\Dree\\Desktop\\ITM_project\\ACTUAL CODING\\CSV'\n",
    "csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "csv_list = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "# Combine all CSVs into one DataFrame\n",
    "agg_csv = pd.concat(csv_list, ignore_index=True)\n",
    "\n",
    "# Filter and clean relevant columns\n",
    "agg_csv = agg_csv[[\n",
    "    'order_date_time',\n",
    "    'category',\n",
    "    'barcode',\n",
    "    'product',\n",
    "    'pc_quantity',\n",
    "    'price',\n",
    "    'total_product_price'\n",
    "]].copy()\n",
    "\n",
    "# Extract date only from datetime\n",
    "agg_csv['order_date'] = pd.to_datetime(agg_csv['order_date_time']).dt.floor('D')\n",
    "\n",
    "# Group by product and date\n",
    "agg_csv = (\n",
    "    agg_csv.drop(columns=['order_date_time'])\n",
    "    .groupby(['barcode', 'product', 'price', 'category', 'order_date'], as_index=False)\n",
    "    [['pc_quantity', 'total_product_price']].sum()\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Feature Engineering Section\n",
    "# ---------------------------\n",
    "\n",
    "# Day of the week & weekend flag\n",
    "agg_csv['day_of_week'] = agg_csv['order_date'].dt.dayofweek\n",
    "agg_csv['if_weekend'] = agg_csv['day_of_week'] >= 5\n",
    "\n",
    "# Extract month\n",
    "agg_csv['month'] = agg_csv['order_date'].dt.month\n",
    "\n",
    "# Sort by barcode and order_date\n",
    "agg_csv = agg_csv.sort_values(by=['barcode', 'order_date'])\n",
    "\n",
    "# Sales from the last order\n",
    "agg_csv['sales_last_order'] = agg_csv.groupby('barcode')['total_product_price'].shift(1)\n",
    "\n",
    "# Rolling 3-order sum and mean (excluding current row)\n",
    "agg_csv['sales_last_3orders'] = (\n",
    "    agg_csv.groupby('barcode')['total_product_price']\n",
    "    .shift(1)\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .sum()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "agg_csv['rolling_mean_3orders'] = (\n",
    "    agg_csv.groupby('barcode')['total_product_price']\n",
    "    .shift(1)\n",
    "    .rolling(window=3, min_periods=1)\n",
    "    .mean()\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Difference from previous order\n",
    "agg_csv['sales_diff_prev_order'] = agg_csv['total_product_price'] - agg_csv['sales_last_order']\n",
    "\n",
    "# Encode category labels for ML\n",
    "label_encoder = LabelEncoder()\n",
    "agg_csv['category_label'] = label_encoder.fit_transform(agg_csv['category'])\n",
    "\n",
    "# Replace NaNs with 0\n",
    "agg_csv = agg_csv.fillna(0)\n",
    "\n",
    "print('Preprocessing completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ab87adf-3c03-4cce-9d56-4e8444859949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Base Model Performance:\n",
      "MAE  = 29.98\n",
      "RMSE = 195.51\n",
      "R²   = 0.7999\n",
      "Tuning model with GridSearchCV...\n",
      "Best parameters found: {'max_depth': 30, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best score (negative MSE): -12815.441993270244\n",
      "Model saved as 'SKU-prediction-model.joblib'.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# MODEL CODE\n",
    "# ---------------------------\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "print('Fetching data...')\n",
    "\n",
    "# -------------------\n",
    "# Feature & Target Setup\n",
    "# -------------------\n",
    "X = agg_csv[[\n",
    "    'price',\n",
    "    'category_label',\n",
    "    'day_of_week',\n",
    "    'if_weekend',\n",
    "    'month',\n",
    "    'sales_last_order',\n",
    "    'sales_last_3orders',\n",
    "    'rolling_mean_3orders',\n",
    "    'sales_diff_prev_order'\n",
    "]]\n",
    "\n",
    "y = agg_csv['pc_quantity']\n",
    "\n",
    "# -------------------\n",
    "# Train/Test Split\n",
    "# -------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)\n",
    "\n",
    "# -------------------\n",
    "# Base Model Training\n",
    "# -------------------\n",
    "base_model = RandomForestRegressor(random_state=77)\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# -------------------\n",
    "# Base Model Evaluation\n",
    "# -------------------\n",
    "y_pred = base_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Base Model Performance:\")\n",
    "print(f\"MAE  = {mae:.2f}\")\n",
    "print(f\"RMSE = {rmse:.2f}\")\n",
    "print(f\"R²   = {r2:.4f}\")\n",
    "\n",
    "# -------------------\n",
    "# Hyperparameter Tuning\n",
    "# -------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'max_features': [None],\n",
    "    'max_depth': [10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print('Tuning model with GridSearchCV...')\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=77),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid.best_score_)\n",
    "\n",
    "# -------------------\n",
    "# Save Best Model\n",
    "# -------------------\n",
    "best_model = grid.best_estimator_\n",
    "joblib.dump(best_model, 'SKU-prediction-model.joblib')\n",
    "\n",
    "print(\"Model saved as 'SKU-prediction-model.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828157c4-f977-48d4-98a5-9bb4b243d122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CSV files...\n",
      "Loading model...\n",
      "Model loaded!\n",
      "Finished SKU: 501120020053\n",
      "Finished SKU: 501120020663\n",
      "Finished SKU: 501120020976\n",
      "Finished SKU: 501120030003\n",
      "Finished SKU: 501120030106\n",
      "Finished SKU: 501120030146\n",
      "Finished SKU: 501120030153\n",
      "Finished SKU: 501120030154\n",
      "Finished SKU: 501120030155\n",
      "Finished SKU: 501120030158\n",
      "Finished SKU: 501120030159\n",
      "Finished SKU: 501120030161\n",
      "Finished SKU: 501120030162\n",
      "Finished SKU: 501120030164\n",
      "Finished SKU: 501120030165\n",
      "Finished SKU: 501120030167\n",
      "Finished SKU: 501120030168\n",
      "Finished SKU: 501120030212\n",
      "Finished SKU: 501120030234\n",
      "Finished SKU: 501120030237\n",
      "Finished SKU: 501120030310\n",
      "Finished SKU: 501120030311\n",
      "Finished SKU: 501120030312\n",
      "Finished SKU: 501317010010\n",
      "Finished SKU: 501317010011\n",
      "Finished SKU: 501317020018\n",
      "Finished SKU: 501317020026\n",
      "Finished SKU: 501317020027\n",
      "Finished SKU: 501318020044\n",
      "Finished SKU: 501318020045\n",
      "Finished SKU: 501318020046\n",
      "Finished SKU: 501318020047\n",
      "Finished SKU: 501318020049\n",
      "Finished SKU: 501318020050\n",
      "Finished SKU: 501318020057\n",
      "Finished SKU: 501318020060\n",
      "Finished SKU: 501318020061\n",
      "Finished SKU: 501318020062\n",
      "Finished SKU: 501515140009\n",
      "Finished SKU: 501515140011\n",
      "Finished SKU: 501515140012\n",
      "Finished SKU: 501515140014\n",
      "Finished SKU: 501515140015\n",
      "Finished SKU: 501515140036\n",
      "Finished SKU: 501515140041\n",
      "Finished SKU: 501515140042\n",
      "Finished SKU: 501515160008\n",
      "Finished SKU: 501515160009\n",
      "Finished SKU: 501718300033\n",
      "Finished SKU: 501718300035\n",
      "Finished SKU: 501718300084\n",
      "Finished SKU: 501718300086\n",
      "Finished SKU: 501817080054\n",
      "Finished SKU: 501817080055\n",
      "Finished SKU: 502017080012\n",
      "Finished SKU: 502017080035\n",
      "Finished SKU: 502017080055\n",
      "Finished SKU: 502017080056\n",
      "Finished SKU: 5011200200254\n",
      "Finished SKU: 5011200200256\n",
      "Finished SKU: 5011200201112\n",
      "Finished SKU: 5011200201113\n",
      "Finished SKU: 5011200201116\n",
      "Finished SKU: 5011200201121\n",
      "Finished SKU: 5011200201123\n",
      "Finished SKU: 5011200201126\n",
      "Finished SKU: 5011200201127\n",
      "Finished SKU: 5011200201129\n",
      "Finished SKU: 5011200201133\n",
      "Finished SKU: 5011200202551\n",
      "Finished SKU: 5011200208371\n",
      "Finished SKU: 5011200208425\n",
      "Finished SKU: 5011200208450\n",
      "Finished SKU: 5011200208465\n",
      "Finished SKU: 5011200211168\n",
      "Finished SKU: 5011200211170\n",
      "Finished SKU: 5011200211174\n",
      "Finished SKU: 5011200211181\n",
      "Finished SKU: 5011200211182\n",
      "Finished SKU: 5011200211183\n",
      "Finished SKU: 5011200211186\n",
      "Finished SKU: 5011200211188\n",
      "Finished SKU: 5011200211194\n",
      "Finished SKU: 5011200217250\n",
      "Finished SKU: 5011200217255\n",
      "Finished SKU: 5011200217569\n",
      "Finished SKU: 5011200217655\n",
      "Finished SKU: 5011200220247\n",
      "Finished SKU: 5011200230010\n",
      "Finished SKU: 5011200230015\n",
      "Finished SKU: 5011200230020\n",
      "Finished SKU: 5011200230030\n",
      "Finished SKU: 5011200230140\n",
      "Finished SKU: 5011200230160\n",
      "Finished SKU: 5011200230324\n",
      "Finished SKU: 5011200242293\n",
      "Finished SKU: 5011200262120\n",
      "Finished SKU: 5011200273201\n",
      "Finished SKU: 5011200273685\n",
      "Finished SKU: 5011200273740\n",
      "Finished SKU: 5011200297320\n",
      "Finished SKU: 5011200297595\n",
      "Finished SKU: 5011200300132\n",
      "Finished SKU: 5011200300137\n",
      "Finished SKU: 5011200300144\n",
      "Finished SKU: 5011200311130\n",
      "Finished SKU: 5011200351214\n",
      "Finished SKU: 5011200354553\n",
      "Finished SKU: 5011200359401\n",
      "Finished SKU: 5011200361512\n",
      "Finished SKU: 5011200361519\n",
      "Finished SKU: 5011200363201\n",
      "Finished SKU: 5011200363202\n",
      "Finished SKU: 5011200363312\n",
      "Finished SKU: 5011200363322\n",
      "Finished SKU: 5011200363332\n",
      "Finished SKU: 5011200363342\n",
      "Finished SKU: 5011200363990\n",
      "Finished SKU: 5011200364042\n",
      "Finished SKU: 5011200364052\n",
      "Finished SKU: 5011200364162\n",
      "Finished SKU: 5011200372012\n",
      "Finished SKU: 5011200372013\n",
      "Finished SKU: 5011200372325\n",
      "Finished SKU: 5011200373543\n",
      "Finished SKU: 5011200374517\n",
      "Finished SKU: 5011200374518\n",
      "Finished SKU: 5011200374519\n",
      "Finished SKU: 5011200379283\n",
      "Finished SKU: 5011200386290\n",
      "Finished SKU: 5011200395203\n",
      "Finished SKU: 5013170103334\n",
      "Finished SKU: 5013170104333\n",
      "Finished SKU: 5013170104335\n",
      "Finished SKU: 5013170104496\n",
      "Finished SKU: 5013170147985\n",
      "Finished SKU: 5013170148230\n",
      "Finished SKU: 5013170148250\n",
      "Finished SKU: 5013170149127\n",
      "Finished SKU: 5013180208720\n",
      "Finished SKU: 5013180208990\n",
      "Finished SKU: 5013180209492\n",
      "Finished SKU: 5013180209496\n",
      "Finished SKU: 5013180209499\n",
      "Finished SKU: 5013180210285\n",
      "Finished SKU: 5013180223263\n",
      "Finished SKU: 5015151407052\n",
      "Finished SKU: 5015151407053\n",
      "Finished SKU: 5015151432201\n",
      "Finished SKU: 5015151432202\n",
      "Finished SKU: 5015151432203\n",
      "Finished SKU: 5015151452010\n",
      "Finished SKU: 5015151454555\n",
      "Finished SKU: 5015151472115\n",
      "Finished SKU: 5015151472130\n",
      "Finished SKU: 5015151472150\n",
      "Finished SKU: 5015151472170\n",
      "Finished SKU: 5015151472230\n",
      "Finished SKU: 5015151472250\n",
      "Finished SKU: 5015151472275\n",
      "Finished SKU: 5015151472288\n",
      "Finished SKU: 5015151473515\n",
      "Finished SKU: 5015151473516\n",
      "Finished SKU: 5015151498522\n",
      "Finished SKU: 5017183060023\n",
      "Finished SKU: 5017183060024\n",
      "Finished SKU: 5017183060025\n",
      "Finished SKU: 5017183060026\n",
      "Finished SKU: 5017183060027\n",
      "Finished SKU: 5017183060032\n",
      "Finished SKU: 5017183081252\n",
      "Finished SKU: 5017183087175\n",
      "Finished SKU: 5017183087179\n",
      "Finished SKU: 5017183087180\n",
      "Finished SKU: 5017183087185\n",
      "Finished SKU: 5017183087186\n",
      "Finished SKU: 5017183093675\n",
      "Finished SKU: 5017183093676\n",
      "Finished SKU: 5017183093678\n",
      "Finished SKU: 5017183093679\n",
      "Finished SKU: 5018170848163\n",
      "Finished SKU: 5018170848295\n",
      "Finished SKU: 5018170848317\n",
      "Finished SKU: 5018170848335\n",
      "Finished SKU: 5020170873540\n",
      "Finished SKU: 5020170873541\n",
      "Finished SKU: 5020170873542\n",
      "Finished SKU: 5020170873544\n",
      "Finished SKU: 5020170874321\n",
      "Finished SKU: 5020170898441\n",
      "Predictions saved to: C:\\Users\\Dree\\Desktop\\ITM_project\\ACTUAL CODING\\predicted_inventory.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print('Fetching CSV files...')\n",
    "\n",
    "# === 1. LOAD & AGGREGATE CSV FILES ===\n",
    "folder = r'C:\\Users\\Dree\\Desktop\\ITM_project\\ACTUAL CODING\\FOR_PREDICTION'\n",
    "csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "csv_list = [pd.read_csv(file) for file in csv_files]\n",
    "agg_csv = pd.concat(csv_list, ignore_index=True)\n",
    "\n",
    "# === 2. CLEAN & GROUP RAW DATA ===\n",
    "agg_csv = agg_csv[[\n",
    "    'order_date_time', 'category', 'barcode', 'product',\n",
    "    'pc_quantity', 'price', 'total_product_price'\n",
    "]].copy()\n",
    "\n",
    "agg_csv['order_date'] = pd.to_datetime(agg_csv['order_date_time']).dt.floor('D')\n",
    "agg_csv = (\n",
    "    agg_csv.drop(columns='order_date_time')\n",
    "           .groupby(['barcode', 'product', 'price', 'category', 'order_date'], as_index=False)\n",
    "           .agg({'pc_quantity': 'sum', 'total_product_price': 'sum'})\n",
    ")\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "agg_csv['day_of_week'] = agg_csv['order_date'].dt.dayofweek\n",
    "agg_csv['if_weekend'] = agg_csv['day_of_week'] >= 5\n",
    "agg_csv['month'] = agg_csv['order_date'].dt.month\n",
    "\n",
    "agg_csv = agg_csv.sort_values(by=['barcode', 'order_date'])\n",
    "\n",
    "agg_csv['sales_last_order'] = agg_csv.groupby('barcode')['total_product_price'].shift(1)\n",
    "\n",
    "agg_csv['sales_last_3orders'] = (\n",
    "    agg_csv.groupby('barcode')['total_product_price']\n",
    "           .shift(1)\n",
    "           .rolling(window=3, min_periods=1)\n",
    "           .sum()\n",
    "           .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "agg_csv['rolling_mean_3orders'] = (\n",
    "    agg_csv.groupby('barcode')['total_product_price']\n",
    "           .shift(1)\n",
    "           .rolling(window=3, min_periods=1)\n",
    "           .mean()\n",
    "           .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "agg_csv['sales_diff_prev_order'] = (\n",
    "    agg_csv['total_product_price'] - agg_csv['sales_last_order']\n",
    ")\n",
    "\n",
    "agg_csv['category_label'] = LabelEncoder().fit_transform(agg_csv['category'])\n",
    "\n",
    "agg_csv = agg_csv.fillna(0)\n",
    "\n",
    "# === 4. BUILD FINAL INPUT FOR PREDICTION ===\n",
    "predict_csv = agg_csv[[\n",
    "    'barcode', 'product', 'price', 'category_label', 'order_date',\n",
    "    'day_of_week', 'if_weekend', 'month',\n",
    "    'sales_last_order', 'sales_last_3orders',\n",
    "    'rolling_mean_3orders', 'sales_diff_prev_order'\n",
    "]].copy()\n",
    "\n",
    "predict_csv = (\n",
    "    predict_csv.loc[predict_csv.groupby('barcode')['order_date'].idxmax()]\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# === 5. LOAD MODEL & RUN PREDICTIONS ===\n",
    "print('Loading model...')\n",
    "model = joblib.load('SKU-prediction-model.joblib')\n",
    "print('Model loaded!')\n",
    "\n",
    "forecast_days = 7\n",
    "future_preds = []\n",
    "\n",
    "for _, row in predict_csv.iterrows():\n",
    "    try:\n",
    "        sku_preds = []\n",
    "        prediction_date = row['order_date']\n",
    "        prev_sales = row['sales_last_order']\n",
    "\n",
    "        sales_history = [\n",
    "            row['sales_last_order'],\n",
    "            row['sales_last_3orders'] - row['sales_last_order'],\n",
    "            row['rolling_mean_3orders']\n",
    "        ]\n",
    "\n",
    "        for _ in range(forecast_days):\n",
    "            prediction_date += timedelta(days=1)\n",
    "            day_of_week = prediction_date.dayofweek\n",
    "            is_weekend = day_of_week >= 5\n",
    "            month = prediction_date.month\n",
    "\n",
    "            X_input = pd.DataFrame([{\n",
    "                'price': row['price'],\n",
    "                'category_label': row['category_label'],\n",
    "                'day_of_week': day_of_week,\n",
    "                'if_weekend': is_weekend,\n",
    "                'month': month,\n",
    "                'sales_last_order': prev_sales,\n",
    "                'sales_last_3orders': sum(sales_history),\n",
    "                'rolling_mean_3orders': np.mean(sales_history),\n",
    "                'sales_diff_prev_order': (\n",
    "                    prev_sales - sales_history[-2] if len(sales_history) > 1 else 0\n",
    "                ),\n",
    "            }])\n",
    "\n",
    "            predicted_sales = max(0, math.ceil(model.predict(X_input)[0]))\n",
    "\n",
    "            sku_preds.append({\n",
    "                'barcode': row['barcode'],\n",
    "                'product': row['product'],\n",
    "                'prediction_date': prediction_date,\n",
    "                'predicted_inventory': predicted_sales\n",
    "            })\n",
    "\n",
    "            sales_history = sales_history[-2:] + [predicted_sales]\n",
    "            prev_sales = predicted_sales\n",
    "\n",
    "        future_preds.extend(sku_preds)\n",
    "        print(f\"Finished SKU: {row['barcode']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on SKU {row['barcode']}: {e}\")\n",
    "\n",
    "# === 6. OUTPUT FINAL PREDICTIONS ===\n",
    "future_df = pd.DataFrame(future_preds)\n",
    "\n",
    "output = (\n",
    "    future_df.groupby(['barcode', 'product'], as_index=False)[['predicted_inventory']]\n",
    "             .sum()\n",
    "             .copy()\n",
    ")\n",
    "\n",
    "# === 7. EXPORT TO CSV ===\n",
    "output_path = r'C:\\Users\\Dree\\Desktop\\ITM_project\\ACTUAL CODING\\predicted_inventory.csv'\n",
    "output.to_csv(output_path, index=False)\n",
    "print(f\"Predictions saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ffcc0a5-df55-429c-bb1a-700c234a8a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>product</th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>predicted_inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>2025-07-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>2025-07-20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>2025-07-13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>2025-07-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         barcode                                 product prediction_date  \\\n",
       "0   501120020053  0053 STAR CHK 'N CHSE NUGGETS 150G X26      2025-07-16   \n",
       "1   501120020053  0053 STAR CHK 'N CHSE NUGGETS 150G X26      2025-07-17   \n",
       "2   501120020053  0053 STAR CHK 'N CHSE NUGGETS 150G X26      2025-07-18   \n",
       "3   501120020053  0053 STAR CHK 'N CHSE NUGGETS 150G X26      2025-07-19   \n",
       "4   501120020053  0053 STAR CHK 'N CHSE NUGGETS 150G X26      2025-07-20   \n",
       "..           ...                                     ...             ...   \n",
       "9   501120020663   0663 STAR, CLASSIC BURGER, 228G X 12.      2025-07-13   \n",
       "10  501120020663   0663 STAR, CLASSIC BURGER, 228G X 12.      2025-07-14   \n",
       "11  501120020663   0663 STAR, CLASSIC BURGER, 228G X 12.      2025-07-15   \n",
       "12  501120020663   0663 STAR, CLASSIC BURGER, 228G X 12.      2025-07-16   \n",
       "13  501120020663   0663 STAR, CLASSIC BURGER, 228G X 12.      2025-07-17   \n",
       "\n",
       "    predicted_inventory  \n",
       "0                     6  \n",
       "1                     1  \n",
       "2                     6  \n",
       "3                     2  \n",
       "4                    16  \n",
       "..                  ...  \n",
       "9                    18  \n",
       "10                    1  \n",
       "11                    1  \n",
       "12                    1  \n",
       "13                    1  \n",
       "\n",
       "[14 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR PREVIEWING\n",
    "# ****simulated predictions\n",
    "future_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccedb0e4-dc75-43e6-8d45-9f2fd1187625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>product</th>\n",
       "      <th>predicted_inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501120020053</td>\n",
       "      <td>0053 STAR CHK 'N CHSE NUGGETS 150G X26</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501120020663</td>\n",
       "      <td>0663 STAR, CLASSIC BURGER, 228G X 12.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501120020976</td>\n",
       "      <td>0976 TJ, CD, JBO, CHEESY PIZZA, 1KGX12, WM.</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>5020170873544</td>\n",
       "      <td>3544 SM COFFEE ORIG, SF, 7GX10X30, TIPID PACK</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>5020170874321</td>\n",
       "      <td>SM COFFEE 3IN1 SF STRONG SUP10S 9GX10X30</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5020170898441</td>\n",
       "      <td>SMC SFREE ORIG, DOUBLE TIPID, 7GX20X15.</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           barcode                                        product  \\\n",
       "0     501120020053         0053 STAR CHK 'N CHSE NUGGETS 150G X26   \n",
       "1     501120020663          0663 STAR, CLASSIC BURGER, 228G X 12.   \n",
       "2     501120020976    0976 TJ, CD, JBO, CHEESY PIZZA, 1KGX12, WM.   \n",
       "..             ...                                            ...   \n",
       "187  5020170873544  3544 SM COFFEE ORIG, SF, 7GX10X30, TIPID PACK   \n",
       "188  5020170874321       SM COFFEE 3IN1 SF STRONG SUP10S 9GX10X30   \n",
       "189  5020170898441        SMC SFREE ORIG, DOUBLE TIPID, 7GX20X15.   \n",
       "\n",
       "     predicted_inventory  \n",
       "0                     38  \n",
       "1                     26  \n",
       "2                    132  \n",
       "..                   ...  \n",
       "187                  101  \n",
       "188                   51  \n",
       "189                  125  \n",
       "\n",
       "[190 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR PREVIEWING\n",
    "pd.set_option('display.max_rows', 6)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7528848-9865-4f6f-ab6b-9c8768ade3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
